{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA4CJku2qjbH"
   },
   "source": [
    "# Описание ДЗ-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAer4qsZqjbJ"
   },
   "source": [
    "В второй домашке необходимо реализовать различные модификации градинетного спуска.\n",
    "\n",
    "За дз можно получить максимум 10 баллов. **Домашки довольно творческие, если замечу копию нотбука у другого студента то максимальный балл сниижается до 3 )**\n",
    "\n",
    "Разбалловка:\n",
    "*   **Воспроизводимость и читабельность кода -  6 баллов** (все воспроизвелось и все понятно для проверяющего - 6 баллов; есть непонятные моменты, но все воспроизвелось - 4 балла; непонятный код и/или воспроизводится с небольшой правкой - 2 балл; непонятный код и/или ничего не воспроизвелось - 0 баллов).\n",
    "*   **Технический отчет - 4 балла** (приведены результаты сравнения и выводы что сделали чтоб перебить baseline\\другую модель, к примеру одна модель лучше/хуже нейронки и тд - 4 балла, только результаты - 2 балл, ничего нет - 0 баллов).\n",
    "\n",
    "\n",
    "Присылать домашки по ссылке https://forms.gle/W8jwbwA4EWagEbX66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeyBrbUK7_lt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSDX4k9g7_lu"
   },
   "source": [
    "## Генерация выборки\n",
    "\n",
    "Для наших целей будем использовать искуственно сгенерированные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ-KTK_C7_lv"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "\n",
    "# keep random_state=42 for deterministic results\n",
    "(X, y) = datasets.make_circles(\n",
    "    n_samples=1024, shuffle=True, noise=0.2, factor=0.4, random_state=42\n",
    ")\n",
    "ind = np.logical_or(y == 1, X[:, 1] > X[:, 0] - 0.5)\n",
    "X = X[ind, :]\n",
    "m = np.array([[1, 1], [-2, 1]])\n",
    "X = preprocessing.scale(X)\n",
    "y = y[ind]\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLx6ZurA7_lw"
   },
   "source": [
    "### [1] Варка фичей\n",
    "\n",
    "Как вы можете заметить, данные не являются линейно разделимыми. Нам придётся добавить в обучающую выборку новые фичи либо использовать нелинейные модели. Предположим, что разделяющая поверхность имеет вид окружности. Добавьте в матрицу признаков дополнительные колонки $x_1^2$, $x_2^2$ и $x_1 \\cdot x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gy-bGbJ47_lw"
   },
   "outputs": [],
   "source": [
    "def expand(X):\n",
    "    \"\"\"\n",
    "    Добавляет квадратичные фичи.\n",
    "    Для каждой строки матрицы находит строку\n",
    "    [feature0, feature1, feature0^2, feature1^2, feature0*feature1, 1]\n",
    "\n",
    "    :param X: матрица фичей, shape [n_samples,2]\n",
    "    :returns: расширенная матрица фичей, shape [n_samples,6]\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAP_Az-N7_lx"
   },
   "source": [
    "### [3] Логистическая регрессия\n",
    "\n",
    "Для классификации будем использовать логистическую регрессию.\n",
    "\n",
    "$$ a(x; w) = \\langle w, x \\rangle $$\n",
    "$$ P( y=1 \\; \\big| \\; x, \\, w) = \\dfrac{1}{1 + \\exp(- \\langle w, x \\rangle)} = \\sigma(\\langle w, x \\rangle)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ikWgpKn7_lx"
   },
   "outputs": [],
   "source": [
    "def probability(X, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу фичей и вектор весов\n",
    "    Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
    "\n",
    "    :param X: расширенная матрица фичей [n_samples,6] (expanded)\n",
    "    :param w: вектор весов [6]\n",
    "    :returns: вектор вероятностей\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf7JEDUo7_ly"
   },
   "source": [
    "Для логистической регрессии оптимальный параметр находится минимизацией кросс-энтропии:\n",
    "\n",
    "$$ L(w) =  - {1 \\over \\ell} \\sum_{i=1}^\\ell \\left[ {y_i \\cdot log P(y_i = 1 \\, | \\, x_i,w) + (1-y_i) \\cdot log (1-P(y_i = 1 \\, | \\, x_i,w))}\\right] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu0FP6AM7_ly"
   },
   "outputs": [],
   "source": [
    "def compute_loss(X, y, w):\n",
    "    \"\"\"\n",
    "    Принимает на вход матрицу весов, вектор ответов и вектор весов.\n",
    "    Выдаёт на выход значение функции потерь, расчитанное по формуле выше.\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYRbj_jw7_lz"
   },
   "source": [
    "Мы будем обучать модель методом градиентного спуска. Для этого нам придётся вычислить градиент функции потерь, представленной выше. Возьмите листочек, ручку и в бой!\n",
    "\n",
    "$$ \\nabla_w L = ...$$\n",
    "\n",
    "Тут обойдёмся даже без матричного дифириенцирования. А вот в следущий раз его не миновать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRpbR5pW7_lz"
   },
   "outputs": [],
   "source": [
    "def compute_grad(X, y, w):\n",
    "    \"\"\"\n",
    "    Нахоит значение градиента.\n",
    "    \"\"\"\n",
    "\n",
    "    # ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UsPjUFF7_l0"
   },
   "source": [
    "Функция ниже предназначена для визуализации процесса обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_2_b9ZI7_l0"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "def visualize(X, y, w, history):\n",
    "    \"\"\"С помощью магии matplolib выдаёт красоты результатов классификации\"\"\"\n",
    "    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history)\n",
    "    plt.grid()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(0, ymax)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkERRU_N7_l0"
   },
   "outputs": [],
   "source": [
    "# убедитесь, что у вас она работает, запустив код ниже\n",
    "# (он отработает если вы верно реализовали expend и probability)\n",
    "dummy_weights = np.linspace(-1, 1, 6)\n",
    "visualize(X, y, dummy_weights, [0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2kWIugW7_l1"
   },
   "source": [
    "## Обучение\n",
    "\n",
    "Пришло время обучить нашу модель. Для этого вам придётся дописать кусочки функций ниже. Обязательно попробуйте поменять гиперпараметры (размер батча и скорость обучения) и посмотреть как будет изменяться анимация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMyLZA8k7_l1"
   },
   "source": [
    "### [2] Mini-batch SGD\n",
    "\n",
    "Берём несколько рандомных наблюдений и ищем градиент по ним!\n",
    "\n",
    "$$ w_t = w_{t-1} - \\eta \\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVgOAq-K7_l2"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta= 0.1\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "\n",
    "    # Ваш код здесь\n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGdrTaYO7_l2"
   },
   "source": [
    "### [2] Momentum SGD\n",
    "\n",
    "Momentum это метод, который помогает стохастическому градиентному спуску сохранять направление движения. Это осуществляется за счёт добавления в выражение дополнительного слагаемого: накопленного за предыдущие шаги градиента с весом $\\alpha$.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$ \\nu_t = \\alpha \\nu_{t-1} + \\eta\\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
    "$$ w_t = w_{t-1} - \\nu_t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5UjKUZQ7_l3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "eta = 0.05\n",
    "alpha = 0.9\n",
    "nu = np.zeros_like(w)\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(n_iter):\n",
    "\n",
    "    # Ваш код здесь\n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RiG9eZB7_l3"
   },
   "source": [
    "### [2] RMSprop\n",
    "\n",
    "В этом блоке реализуем RMSprop. Эта вариация градиентного спуска позволяет изменять скорость обучения индивидуально для каждого параметра.\n",
    "\n",
    "$$ G_t^j = \\alpha G_{t-1}^j + (1 - \\alpha) g_{tj}^2 $$\n",
    "$$ w_t^j = w_{t-1}^j - \\dfrac{\\eta}{\\sqrt{G_t^j + \\varepsilon}} g_{tj} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQMnZg-87_l4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "w = np.array([0, 0, 0, 0, 0, 1.])\n",
    "\n",
    "eta = 0.1\n",
    "alpha = 0.9\n",
    "g2 = np.zeros_like(w)\n",
    "eps = 1e-8\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "\n",
    "    # Ваш код здесь\n",
    "\n",
    "visualize(X, y, w, loss)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1Bv45bO7_l4"
   },
   "source": [
    "Как траектории обучения различных вариаций градиентного спуска различаются между собой? Ожидаемо ли это? Почему? Что нужно сделать, чтобы реализовать Adam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzFX1l2r7_l5"
   },
   "source": [
    "### [2] За каждую адекватную вариацию\n",
    "\n",
    "Если понравилось реализовывать свои градиентные спуски и ты находишься от них под глубоким впечатлением, я могу накинуть дополнительные баллы за реализацию каждой новой адекватной вариации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Igchxlon7_l5"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
